{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n"
      ],
      "metadata": {
        "id": "RVJjNRw9Z0yd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o88xZJAHW9SP",
        "outputId": "5438895e-965f-4674-f448-1caca8c4db63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"I completed my bachelor's degree in Computer Science engineering at CU.\"\n"
      ],
      "metadata": {
        "id": "F2nULVkFW_pZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(sample_text)\n",
        "print(\"Basic Tokenization:\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAF8BscqW_3R",
        "outputId": "bd779ecd-f62d-4fc9-8dd8-6930aa7c1d00"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic Tokenization:\n",
            "['I', 'completed', 'my', 'bachelor', \"'s\", 'degree', 'in', 'Computer', 'Science', 'engineering', 'at', 'CU', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(sample_text)\n",
        "print(\"\\nSentence Tokenization:\")\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGxaENnYXAHr",
        "outputId": "21113cca-591b-4431-8718-fc73070db631"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence Tokenization:\n",
            "[\"I completed my bachelor's degree in Computer Science engineering at CU.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tokens = [token for token in tokens if token.isalnum()]\n",
        "print(\"\\nCustom Tokenization:\")\n",
        "print(custom_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOIoxxFlXAZu",
        "outputId": "96740c6a-c90e-4dd7-8421-832974fe2ebe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom Tokenization:\n",
            "['I', 'completed', 'my', 'bachelor', 'degree', 'in', 'Computer', 'Science', 'engineering', 'at', 'CU']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "print(\"\\nStemming:\")\n",
        "print(stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN9kU2XMXJYC",
        "outputId": "3c699d33-259c-4335-a78f-c25593245dbd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming:\n",
            "['i', 'complet', 'my', 'bachelor', \"'s\", 'degre', 'in', 'comput', 'scienc', 'engin', 'at', 'cu', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(\"\\nLemmatization:\")\n",
        "print(lemmatized_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNCEdkn_XMDq",
        "outputId": "94c08618-5692-4415-ed94-13246b0b8b70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lemmatization:\n",
            "['I', 'completed', 'my', 'bachelor', \"'s\", 'degree', 'in', 'Computer', 'Science', 'engineering', 'at', 'CU', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "print(\"\\nRemoving Stopwords:\")\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpK3HRi1XOD6",
        "outputId": "b9ce2465-1228-45e1-c869-f9b5fe94879a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Removing Stopwords:\n",
            "['completed', 'bachelor', \"'s\", 'degree', 'Computer', 'Science', 'engineering', 'CU', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = pos_tag(tokens)\n",
        "print(\"\\nPart-of-Speech Tagging:\")\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW-2xG9UZd2B",
        "outputId": "a0eb378d-8a36-4aca-9db2-6a8627ec3f15"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Part-of-Speech Tagging:\n",
            "[('I', 'PRP'), ('completed', 'VBD'), ('my', 'PRP$'), ('bachelor', 'NN'), (\"'s\", 'POS'), ('degree', 'NN'), ('in', 'IN'), ('Computer', 'NNP'), ('Science', 'NNP'), ('engineering', 'NN'), ('at', 'IN'), ('CU', 'NNP'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}
