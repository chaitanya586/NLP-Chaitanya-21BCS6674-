{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYghZESN4QZX",
        "outputId": "43191dc7-fee6-4e46-c83d-3ced12c034b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download punkt tokenizer if not already downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Take input from the user\n",
        "text = input(\"Enter the text: \")\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "# Create a frequency distribution of words\n",
        "fdist = FreqDist(words)\n",
        "\n",
        "# Display the frequency distribution\n",
        "print(\"Word\\tFrequency\")\n",
        "for word, frequency in fdist.items():\n",
        "    print(f\"{word}\\t{frequency}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QEgB9er4cBF",
        "outputId": "b0e71177-c0e0-4f60-9ac4-24e31d650ceb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: Natural language processing (NLP) is an interdisciplinary subfield of computer science and information retrieval. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of \"understanding\"[citation needed] the contents of documents, including the contextual nuances of the language within them. To this end, natural language processing often borrows ideas from theoretical linguistics. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
            "Word\tFrequency\n",
            "Natural\t1\n",
            "language\t5\n",
            "processing\t3\n",
            "(\t2\n",
            "NLP\t1\n",
            ")\t2\n",
            "is\t3\n",
            "an\t1\n",
            "interdisciplinary\t1\n",
            "subfield\t1\n",
            "of\t4\n",
            "computer\t2\n",
            "science\t1\n",
            "and\t5\n",
            "information\t2\n",
            "retrieval\t1\n",
            ".\t7\n",
            "It\t2\n",
            "primarily\t1\n",
            "concerned\t1\n",
            "with\t1\n",
            "giving\t1\n",
            "computers\t1\n",
            "the\t6\n",
            "ability\t1\n",
            "to\t1\n",
            "support\t1\n",
            "manipulate\t1\n",
            "human\t1\n",
            "involves\t1\n",
            "natural\t2\n",
            "datasets\t1\n",
            ",\t6\n",
            "such\t1\n",
            "as\t3\n",
            "text\t1\n",
            "corpora\t2\n",
            "or\t2\n",
            "speech\t1\n",
            "using\t1\n",
            "either\t1\n",
            "rule-based\t1\n",
            "probabilistic\t1\n",
            "i.e\t1\n",
            "statistical\t1\n",
            "most\t1\n",
            "recently\t1\n",
            "neural\t1\n",
            "network-based\t1\n",
            "machine\t1\n",
            "learning\t1\n",
            "approaches\t1\n",
            "The\t2\n",
            "goal\t1\n",
            "a\t1\n",
            "capable\t1\n",
            "``\t1\n",
            "understanding\t1\n",
            "''\t1\n",
            "[\t1\n",
            "citation\t1\n",
            "needed\t1\n",
            "]\t1\n",
            "contents\t1\n",
            "documents\t3\n",
            "including\t1\n",
            "contextual\t1\n",
            "nuances\t1\n",
            "within\t1\n",
            "them\t1\n",
            "To\t1\n",
            "this\t1\n",
            "end\t1\n",
            "often\t1\n",
            "borrows\t1\n",
            "ideas\t1\n",
            "from\t1\n",
            "theoretical\t1\n",
            "linguistics\t1\n",
            "technology\t1\n",
            "can\t1\n",
            "then\t1\n",
            "accurately\t1\n",
            "extract\t1\n",
            "insights\t1\n",
            "contained\t1\n",
            "in\t1\n",
            "well\t1\n",
            "categorize\t1\n",
            "organize\t1\n",
            "themselves\t1\n"
          ]
        }
      ]
    }
  ]
}